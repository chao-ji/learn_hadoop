Performs Clustering using K-Means Clustering

Input && Output:
  -data: file that contains observations to be clustered
    format:
    <id><tab><partition><list of features in 'd' dimensional space separated by tab>
    example:
    0	0	1.0	1.0
    1	0	1.5	2.0
    2	1	3.0	4.0
    3	1	5.0	7.0
    4	1	3.5	5.0
    5	1	4.5	5.0
    6	1	3.5	4.5

    Observation with id '0' is initially assigned to partition '0', and is described by vector [1.0, 1.0]
    
  -center: intermediate file generated by the program that contains cluster centers
    format:
    <id><tab><list of features in 'd' dimensional space separated by tab>
    
Algorithm:
  The algorithm consists of two mapreduce jobs:
  1. Update job
    Given the current assignments of observations (data), compute the updated center/mean of each cluster (center)
    -Mapper:
      (key, value) = (<partition>, <id><tab><partition><list of features in 'd' dimensional space separated by tab> + "\t1")
        for records in data. The "1" is used as a count for computing the mean
    -Reducer:
      (key, value) = (<partition>, <list of UPDATED features in 'd' dimensional space separated by tab>)
  
  2. Assignment job
    Given the current cluster center, update the assignment of observations to the nearest cluster center
    -Mapper:
      (key, value) = (<id>, "D" + <id><tab><partition><list of features in 'd' dimensional space separated by tab>)
        for records in "data"
        
      (key, value) = (<data id>, "C" + <id><tab><list of features in 'd' dimensional space separated by tab>)
        for records in "center", where <data id> = 0, 1, ... the number of observations - 1
        
    -Reducer:
      Find the cluster/mean that is nearest to the observation
      (key, value) = (<id><tab><partition><list of features in 'd' dimensional space separated by tab>, NullWritable)
        where <partition> has been updated to the nearest cluster center.
        
  3.  The program reads in the "data", "center", the number of observations, the maximum number of iterations.
      Mapreduce built-in counters are used to count the number of partition updates in the assign job.
      The program terminates if there is no update in the partition number for any observation.
